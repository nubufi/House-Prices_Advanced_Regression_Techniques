{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"./dataset/processed_training_data.csv\")\n",
    "test_data = pd.read_csv(\"./dataset/processed_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "numerical_features = training_data.select_dtypes(include='number').columns.tolist()\n",
    "categorical_features = training_data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('scaler',StandardScaler(),numerical_features),\n",
    "            ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "    )\n",
    "\n",
    "processed_features = column_transformer.fit_transform(training_data).toarray()\n",
    "\n",
    "# Get the list of all the features after transformation\n",
    "encoded_cat_columns = column_transformer.named_transformers_['encoder'] \\\n",
    "                                          .get_feature_names_out(input_features=categorical_features)\n",
    "all_column_names = numerical_features+list(encoded_cat_columns)\n",
    "processed_df = pd.DataFrame(processed_features, columns=all_column_names)\n",
    "\n",
    "# Process the test data\n",
    "processed_test_data = test_data.copy()\n",
    "processed_test_data[\"SalePrice\"] = np.ones(test_data.shape[0])\n",
    "processed_test_data.drop(\"Id\", axis=1, inplace=True)\n",
    "\n",
    "processed_test_features = column_transformer.transform(processed_test_data).toarray()\n",
    "processed_test_df = pd.DataFrame(processed_test_features, columns=all_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "    input_shape = processed_df.shape[1]-1\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(input_shape, activation='relu', input_shape=[input_shape]),\n",
    "    ])\n",
    "    \n",
    "    hp_num_layers = hp.Int('num_layers', min_value=1, max_value=5, step=1)\n",
    "\n",
    "    for layer in range(hp_num_layers):\n",
    "        # Tune the number of units in each dense layer\n",
    "        hp_units = hp.Int(f'units_{layer}', min_value=32, max_value=512, step=32)\n",
    "        \n",
    "        # Add the dense layer with the specified number of units and ReLU activation\n",
    "        model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.mae,\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_df.drop(\"SalePrice\", axis=1)\n",
    "y = processed_df[\"SalePrice\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuner_dir\\house_price_prediction\\tuner0.json\n",
      "Epoch 34: early stopping\n",
      "Epoch 88: early stopping\n",
      "Epoch 73: early stopping\n",
      "Epoch 58: early stopping\n",
      "Epoch 68: early stopping\n",
      "Epoch 24: early stopping\n",
      "Epoch 30: early stopping\n",
      "Epoch 30: early stopping\n",
      "Epoch 73: early stopping\n",
      "Epoch 55: early stopping\n",
      "Epoch 75: early stopping\n",
      "Epoch 38: early stopping\n",
      "Epoch 34: early stopping\n",
      "Epoch 38: early stopping\n",
      "Epoch 25: early stopping\n",
      "Epoch 53: early stopping\n",
      "Epoch 69: early stopping\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                    patience=20,\n",
    "                                    verbose=1)\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "        objective='val_loss',\n",
    "        max_epochs=100,\n",
    "        factor=3,\n",
    "        directory='tuner_dir',\n",
    "        project_name='house_price_prediction')\n",
    "\n",
    "tuner.search(x_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Test Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 3, 'units_0': 64, 'learning_rate': 0.01, 'units_1': 288, 'units_2': 32, 'units_3': 448, 'units_4': 384, 'tuner/epochs': 34, 'tuner/initial_epoch': 12, 'tuner/bracket': 4, 'tuner/round': 3, 'tuner/trial_id': '0134'}\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model with Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2b5adc5e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                    patience=20,\n",
    "                                    verbose=1)\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X,y,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test = processed_test_df.drop(\"SalePrice\", axis=1)\n",
    "\n",
    "pred_scaled = model.predict(x_test)\n",
    "\n",
    "test_data[\"SalePrice\"] = pred_scaled.reshape(-1)\n",
    "test_data[numerical_features] = column_transformer.named_transformers_['scaler'].inverse_transform(test_data[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export To Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"Id\"] = test_data[\"Id\"]\n",
    "submission[\"SalePrice\"] = test_data[\"SalePrice\"]\n",
    "submission[\"SalePrice\"].fillna(submission[\"SalePrice\"].mean(),inplace=True)\n",
    "submission.to_csv(\"./dataset/submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
